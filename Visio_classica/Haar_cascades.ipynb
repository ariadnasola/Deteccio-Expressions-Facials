{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascade amb SVC (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import kagglehub\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carreguem dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = kagglehub.dataset_download(\"tapakah68/facial-emotion-recognition\")\n",
    "people_dirs = glob(os.path.join(source_dir+'/images', \"*\"))\n",
    "\n",
    "# Path al dataset organitzat\n",
    "dest_dir = \"/kaggle/working/organized_by_emotion\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# Possibles emocions\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "\n",
    "# Organitzem emocions per carpetes\n",
    "for emotion in emotions:\n",
    "    os.makedirs(os.path.join(dest_dir, emotion), exist_ok=True)\n",
    "\n",
    "\n",
    "# Movem les emocions a les carpetes\n",
    "for person_path in people_dirs:\n",
    "    if os.path.isdir(person_path):\n",
    "        person_id = os.path.basename(person_path)\n",
    "        emotion_images = glob(os.path.join(person_path, \"*.jpg\"))\n",
    "\n",
    "        for img_path in emotion_images:\n",
    "            emotion = os.path.splitext(os.path.basename(img_path))[0].capitalize()\n",
    "            if emotion in emotions:\n",
    "                new_filename = f\"{person_id}.jpg\"\n",
    "                dest_path = os.path.join(dest_dir, emotion, new_filename)\n",
    "                shutil.copy(img_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busquem possibles boques i seleccionem la millor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier('\\Predictors\\haarcascade_mcs_mouth.xml')\n",
    "def extract_best_mouth(face_gray, mouths):\n",
    "    \"\"\"Boca centrada i cap avall de la cara.\"\"\"\n",
    "    h, w = face_gray.shape\n",
    "    center_x, bottom_y = w // 2, int(h * 0.75)\n",
    "\n",
    "    best_mouth = None\n",
    "    min_dist = float('inf')\n",
    "    for (mx, my, mw, mh) in mouths:\n",
    "        mouth_cx = mx + mw // 2\n",
    "        mouth_cy = my + mh // 2\n",
    "        dist = (mouth_cx - center_x) ** 2 + (mouth_cy - bottom_y) ** 2\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_mouth = (mx, my, mw, mh)\n",
    "    return best_mouth\n",
    "\n",
    "def extract_mouth_hog(face_gray):\n",
    "    mouths = mouth_cascade.detectMultiScale(face_gray, 1.1, 4)\n",
    "    if len(mouths) == 0:\n",
    "        return None\n",
    "\n",
    "    best_mouth = extract_best_mouth(face_gray, mouths)\n",
    "    if best_mouth is None:\n",
    "        return None\n",
    "\n",
    "    mx, my, mw, mh = best_mouth\n",
    "    mouth_roi = face_gray[my:my+mh, mx:mx+mw]\n",
    "    resized = cv2.resize(mouth_roi, (64, 64))  # bigger for better HOG\n",
    "    features = hog(resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencem entrenament amb SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "DATA_DIR = '/kaggle/working/organized_by_emotion'\n",
    "OUTPUT_FILE = 'mouth_vectors_all_emotions.pkl'\n",
    "\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_path = os.path.join(DATA_DIR, emotion)\n",
    "    files = sorted(os.listdir(emotion_path))[:12]  # 12 persones per train\n",
    "\n",
    "    for filename in files:\n",
    "        img_path = os.path.join(emotion_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            hog_features = extract_mouth_hog(face_gray)\n",
    "            if hog_features is not None:\n",
    "                X_train.append(hog_features)\n",
    "                y_train.append(emotion)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(X_train, y_train_enc)\n",
    "\n",
    "with open('emotion_svm.pkl', 'wb') as f:\n",
    "    pickle.dump((clf, le), f)\n",
    "\n",
    "print(f\"Train on {len(X_train)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "DATA_DIR = '/kaggle/working/organized_by_emotion'\n",
    "\n",
    "with open('emotion_svm.pkl', 'rb') as f:\n",
    "    clf, le = pickle.load(f)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_path = os.path.join(DATA_DIR, emotion)\n",
    "    files = sorted(os.listdir(emotion_path))[12:18]  # ultimes 6 persones per test\n",
    "\n",
    "    for filename in files:\n",
    "        img_path = os.path.join(emotion_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            hog_features = extract_mouth_hog(face_gray)\n",
    "            if hog_features is not None:\n",
    "                pred = clf.predict([hog_features])[0]\n",
    "                pred_label = le.inverse_transform([pred])[0]\n",
    "                y_true.append(emotion)\n",
    "                y_pred.append(pred_label)\n",
    "\n",
    "# resultats\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=emotions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=emotions, yticklabels=emotions)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix: SVM Mouth-Based Emotion Recognition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascade amb distancia euclidieana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "DATA_DIR = '/kaggle/working/organized_by_emotion'\n",
    "OUTPUT_FILE = 'mouth_vectors_all_emotions.pkl'\n",
    "\n",
    "# List of emotions (must match folder names)\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "\n",
    "emotion_vectors = []  # List of tuples: (vector, emotion_label)\n",
    "\n",
    "def detect_mouths(gray_face):\n",
    "    mouths = mouth_cascade.detectMultiScale(gray_face, 1.1, 4)\n",
    "    mouth_vectors = []\n",
    "\n",
    "    for (mx, my, mw, mh) in mouths:\n",
    "        mouth_region = gray_face[my:my+mh, mx:mx+mw]\n",
    "        resized = cv2.resize(mouth_region, (16, 16))\n",
    "        vector = resized.flatten().astype(np.float32)\n",
    "        mouth_vectors.append(vector)\n",
    "\n",
    "    return mouth_vectors\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(DATA_DIR, emotion)\n",
    "    if not os.path.exists(emotion_dir):\n",
    "        print(f\"Emocio {emotion} no existent\")\n",
    "        continue\n",
    "\n",
    "    files = sorted(os.listdir(emotion_dir))[:12]\n",
    "\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(emotion_dir, filename)\n",
    "\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            mouths = detect_mouths(face_gray)\n",
    "\n",
    "            for vec in mouths:\n",
    "                emotion_vectors.append((vec, emotion))\n",
    "\n",
    "print(f\"Guardats {len(emotion_vectors)} vectors.\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'wb') as f:\n",
    "    pickle.dump(emotion_vectors, f)\n",
    "\n",
    "print(f\"Dataset saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mouth_vectors_all_emotions.pkl', 'rb') as f:\n",
    "    train_vectors = pickle.load(f)\n",
    "\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "DATA_DIR = '/kaggle/working/organized_by_emotion'\n",
    "\n",
    "def detect_mouths(gray_face):\n",
    "    mouths = mouth_cascade.detectMultiScale(gray_face, 1.1, 4)\n",
    "    mouth_vectors = []\n",
    "    for (mx, my, mw, mh) in mouths:\n",
    "        mouth_region = gray_face[my:my+mh, mx:mx+mw]\n",
    "        resized = cv2.resize(mouth_region, (16, 16))\n",
    "        vector = resized.flatten().astype(np.float32)\n",
    "        mouth_vectors.append(vector)\n",
    "    return mouth_vectors\n",
    "\n",
    "def find_closest_emotion(test_vec, train_vectors):\n",
    "    min_dist = float('inf')\n",
    "    predicted_emotion = 'unknown'\n",
    "    for vec, label in train_vectors:\n",
    "        dist = np.linalg.norm(test_vec - vec)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            predicted_emotion = label\n",
    "    return predicted_emotion\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(DATA_DIR, emotion)\n",
    "    files = sorted(os.listdir(emotion_dir))[12:18]  \n",
    "    for filename in files:\n",
    "        file_path = os.path.join(emotion_dir, filename)\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            mouth_vecs = detect_mouths(face_gray)\n",
    "\n",
    "            for mv in mouth_vecs:\n",
    "                predicted = find_closest_emotion(mv, train_vectors)\n",
    "                y_true.append(emotion)\n",
    "                y_pred.append(predicted)\n",
    "\n",
    "print(f\"\\n=== Classification Report ===\\n\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=emotions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=emotions, yticklabels=emotions)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Emotion Classification Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
