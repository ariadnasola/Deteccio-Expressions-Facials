{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carreguem dlib detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import kagglehub\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor(\"Predictors\\shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectem cara dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mouth_dlib(img_gray):\n",
    "    faces = dlib_detector(img_gray)\n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected.\")\n",
    "        return None\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = landmark_predictor(img_gray, face)\n",
    "\n",
    "        mouth_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "        mouth_np = np.array(mouth_points)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(mouth_np)\n",
    "        mouth_roi = img_gray[y:y+h, x:x+w]\n",
    "\n",
    "        if mouth_roi.size == 0:\n",
    "            print(\"Empty mouth.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            resized = cv2.resize(mouth_roi, (64, 64))\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return None\n",
    "\n",
    "        features = hog(resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        return features\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrreguem Facial emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = kagglehub.dataset_download(\"tapakah68/facial-emotion-recognition\")\n",
    "people_dirs = glob(os.path.join(source_dir+'/images', \"*\"))\n",
    "\n",
    "# Path al dataset organitzat\n",
    "dest_dir = \"/kaggle/working/organized_by_emotion\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# Possibles emocions\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "\n",
    "# Organitzem emocions per carpetes\n",
    "for emotion in emotions:\n",
    "    os.makedirs(os.path.join(dest_dir, emotion), exist_ok=True)\n",
    "\n",
    "\n",
    "# Movem les emocions a les carpetes\n",
    "for person_path in people_dirs:\n",
    "    if os.path.isdir(person_path):\n",
    "        person_id = os.path.basename(person_path)\n",
    "        emotion_images = glob(os.path.join(person_path, \"*.jpg\"))\n",
    "\n",
    "        for img_path in emotion_images:\n",
    "            emotion = os.path.splitext(os.path.basename(img_path))[0].capitalize()\n",
    "            if emotion in emotions:\n",
    "                new_filename = f\"{person_id}.jpg\"\n",
    "                dest_path = os.path.join(dest_dir, emotion, new_filename)\n",
    "                shutil.copy(img_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train amb tres possibles models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, file_path, emotions):\n",
    "  X_train, y_train = [], []\n",
    "\n",
    "  for emotion in emotions:\n",
    "      emotion_path = os.path.join(file_path, emotion)\n",
    "      files = sorted(os.listdir(emotion_path))[:12]  #Agafem les 12 pirmeres persones per fer el train\n",
    "\n",
    "      for filename in files:\n",
    "          img_path = os.path.join(emotion_path, filename)\n",
    "          img = cv2.imread(img_path)\n",
    "          if img is None:\n",
    "              continue\n",
    "          gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "          gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "          features = extract_mouth_dlib(gray)\n",
    "\n",
    "          if features is not None:\n",
    "              X_train.append(features)\n",
    "              y_train.append(emotion)\n",
    "\n",
    "  # Encode les etiquetes\n",
    "  le = LabelEncoder()\n",
    "  y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "  # Entrenem el model corresponent\n",
    "  if model == 'rf':\n",
    "      rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "      rf.fit(X_train, y_train_enc)\n",
    "\n",
    "  elif model == 'knn':\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "    knn.fit(X_train, y_train_enc)\n",
    "\n",
    "  elif model == 'svm':\n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "    clf.fit(X_train, y_train_enc)\n",
    "\n",
    "  else:\n",
    "      raise ValueError(\"Model not available\")\n",
    "\n",
    "  #Guardem el model\n",
    "  with open('emotion_rf.pkl', 'wb') as f:\n",
    "      pickle.dump((rf, le), f)\n",
    "\n",
    "  print(f\"Model trained ({model}) on {len(X_train)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test amb tres possibles models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, file_path, emotions):\n",
    "  with open('emotion_rf.pkl', 'rb') as f:\n",
    "    rf, le = pickle.load(f)\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for emotion in emotions:\n",
    "        emotion_path = os.path.join(file_path, emotion)\n",
    "        files = sorted(os.listdir(emotion_path))[12:18]  # Últimes 6 persones per testing\n",
    "\n",
    "        for filename in files:\n",
    "            img_path = os.path.join(emotion_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            features = extract_mouth_dlib(gray)\n",
    "\n",
    "            if features is not None:\n",
    "                if model == 'rf':\n",
    "                    pred = rf.predict([features])[0]\n",
    "                elif model == 'knn':\n",
    "                    pred = knn.predict([features])[0]\n",
    "                elif model == 'svm':\n",
    "                    pred = clf.predict([features])[0]\n",
    "\n",
    "                pred_label = le.inverse_transform([pred])[0]\n",
    "                y_true.append(emotion)\n",
    "                y_pred.append(pred_label)\n",
    "\n",
    "    #Resultats\n",
    "    print(f\"\\n Results with model {model}:\\n\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    #Matriu de confusió\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=emotions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=emotions, yticklabels=emotions)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{model} Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova (podem canviar al model que vulguem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral', 'Contempt']\n",
    "DATA_DIR = '/kaggle/working/organized_by_emotion'\n",
    "\n",
    "#model pot ser: rf, svm, knn\n",
    "test(model='rf', file_path=DATA_DIR, emotions=emotions)\n",
    "train(model='rf', file_path=DATA_DIR, emotions=emotions)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
